#!/usr/bin/env python3
"""
LVLMè¯„ä¼°ç»“æœæ±‡æ€»è„šæœ¬
"""

import os
import argparse
import json
import glob
from datetime import datetime
from collections import defaultdict


def load_lvlm_results(input_dir):
    """åŠ è½½æ‰€æœ‰LVLMè¯„ä¼°ç»“æœ"""
    results = defaultdict(lambda: defaultdict(lambda: defaultdict(dict)))
    
    # éå†VQAå’ŒCaptionå­ç›®å½•
    for task_dir in ['vqa', 'caption']:
        task_path = os.path.join(input_dir, task_dir)
        if not os.path.exists(task_path):
            continue
        
        # æŸ¥æ‰¾æ‰€æœ‰ç»“æœæ–‡ä»¶
        result_files = glob.glob(os.path.join(task_path, '*_results.json'))
        
        for result_file in result_files:
            with open(result_file, 'r') as f:
                data = json.load(f)
            
            # æå–ä¿¡æ¯
            clip_name = os.path.basename(data['clip_checkpoint']).replace('.pt', '')
            lvlm_type = data['lvlm_type']
            dataset = data['dataset']
            eps = data['eps']
            
            key = f"{dataset}_eps{eps}"
            
            # å­˜å‚¨ç»“æœ
            results[clip_name][lvlm_type][task_dir][key] = data
    
    return results


def generate_markdown_report(results):
    """ç”ŸæˆMarkdownæ ¼å¼æŠ¥å‘Š"""
    md = []
    
    md.append("# LVLMé²æ£’æ€§è¯„ä¼°æŠ¥å‘Š (FAREè®¾ç½®)\n")
    md.append(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
    md.append("---\n\n")
    
    # VQAç»“æœ
    md.append("## è§†è§‰é—®ç­” (VQA)\n\n")
    
    for lvlm_type in ['llava', 'flamingo']:
        md.append(f"### {lvlm_type.upper()}\n\n")
        md.append("| CLIP Model | Dataset | Eps | Clean Acc | Robust Acc | Acc Drop |\n")
        md.append("|------------|---------|-----|-----------|------------|----------|\n")
        
        for clip_name in sorted(results.keys()):
            if lvlm_type in results[clip_name]:
                if 'vqa' in results[clip_name][lvlm_type]:
                    for key, data in sorted(results[clip_name][lvlm_type]['vqa'].items()):
                        dataset = data['dataset']
                        eps = data['eps']
                        clean_acc = data.get('clean_acc', 0) * 100
                        robust_acc = data.get('robust_acc', 0) * 100
                        drop = clean_acc - robust_acc
                        
                        md.append(f"| {clip_name} | {dataset} | {eps}/255 | "
                                 f"{clean_acc:.2f}% | {robust_acc:.2f}% | {drop:.2f}% |\n")
        
        md.append("\n")
    
    # Captionç»“æœ
    md.append("## å›¾åƒæè¿° (Caption)\n\n")
    
    for lvlm_type in ['llava', 'flamingo']:
        md.append(f"### {lvlm_type.upper()}\n\n")
        md.append("| CLIP Model | Dataset | Eps | Clean CIDEr | Robust CIDEr | CIDEr Drop |\n")
        md.append("|------------|---------|-----|-------------|--------------|------------|\n")
        
        for clip_name in sorted(results.keys()):
            if lvlm_type in results[clip_name]:
                if 'caption' in results[clip_name][lvlm_type]:
                    for key, data in sorted(results[clip_name][lvlm_type]['caption'].items()):
                        dataset = data['dataset']
                        eps = data['eps']
                        clean_cider = data.get('clean_cider', 0)
                        robust_cider = data.get('robust_cider', 0)
                        drop_pct = (clean_cider - robust_cider) / clean_cider * 100 if clean_cider > 0 else 0
                        
                        md.append(f"| {clip_name} | {dataset} | {eps}/255 | "
                                 f"{clean_cider:.4f} | {robust_cider:.4f} | {drop_pct:.2f}% |\n")
        
        md.append("\n")
    
    # å¯¹æ¯”æ€»ç»“
    md.append("## å¯¹æ¯”æ€»ç»“\n\n")
    md.append("### å¹³å‡æ€§èƒ½\n\n")
    
    # è®¡ç®—å¹³å‡æ€§èƒ½
    avg_stats = defaultdict(lambda: defaultdict(lambda: {'clean': [], 'robust': []}))
    
    for clip_name in results.keys():
        for lvlm_type in results[clip_name].keys():
            # VQAå¹³å‡
            if 'vqa' in results[clip_name][lvlm_type]:
                for data in results[clip_name][lvlm_type]['vqa'].values():
                    avg_stats[clip_name][f"{lvlm_type}_vqa"]['clean'].append(data.get('clean_acc', 0))
                    avg_stats[clip_name][f"{lvlm_type}_vqa"]['robust'].append(data.get('robust_acc', 0))
            
            # Captionå¹³å‡
            if 'caption' in results[clip_name][lvlm_type]:
                for data in results[clip_name][lvlm_type]['caption'].values():
                    avg_stats[clip_name][f"{lvlm_type}_caption"]['clean'].append(data.get('clean_cider', 0))
                    avg_stats[clip_name][f"{lvlm_type}_caption"]['robust'].append(data.get('robust_cider', 0))
    
    md.append("| CLIP Model | Task | Clean | Robust | Drop |\n")
    md.append("|------------|------|-------|--------|------|\n")
    
    for clip_name in sorted(avg_stats.keys()):
        for task_key in sorted(avg_stats[clip_name].keys()):
            stats = avg_stats[clip_name][task_key]
            avg_clean = sum(stats['clean']) / len(stats['clean']) if stats['clean'] else 0
            avg_robust = sum(stats['robust']) / len(stats['robust']) if stats['robust'] else 0
            
            if 'vqa' in task_key:
                avg_clean *= 100
                avg_robust *= 100
                drop = avg_clean - avg_robust
                md.append(f"| {clip_name} | {task_key} | {avg_clean:.2f}% | {avg_robust:.2f}% | {drop:.2f}% |\n")
            else:
                drop_pct = (avg_clean - avg_robust) / avg_clean * 100 if avg_clean > 0 else 0
                md.append(f"| {clip_name} | {task_key} | {avg_clean:.4f} | {avg_robust:.4f} | {drop_pct:.2f}% |\n")
    
    md.append("\n")
    
    # æ·»åŠ è¯´æ˜
    md.append("---\n\n")
    md.append("## è¯„ä¼°è¯´æ˜\n\n")
    md.append("- **VQAä»»åŠ¡**: ä½¿ç”¨FAREä¸‰é˜¶æ®µæ”»å‡»pipeline (åŠç²¾åº¦APGD â†’ å•ç²¾åº¦APGD â†’ Targeted)\n")
    md.append("- **Captionä»»åŠ¡**: ä½¿ç”¨FAREä¸¤é˜¶æ®µæ”»å‡»pipeline (åŠç²¾åº¦APGD â†’ å•ç²¾åº¦APGD)\n")
    md.append("- **è¯„ä¼°æ ·æœ¬**: VQAå’ŒCaptionå„500ä¸ªéšæœºæ ·æœ¬\n")
    md.append("- **LVLMæ¨¡å‹**: LLaVA-1.5 7B, OpenFlamingo 9B\n")
    md.append("- **æ”»å‡»ç±»å‹**: ç°ç›’æ”»å‡»ï¼ˆä»…æ”»å‡»CLIP vision encoderï¼‰\n")
    
    return ''.join(md)


def main():
    parser = argparse.ArgumentParser(description='æ±‡æ€»LVLMè¯„ä¼°ç»“æœ')
    parser.add_argument('--input_dir', type=str, required=True,
                       help='è¯„ä¼°ç»“æœç›®å½•')
    parser.add_argument('--output_file', type=str, default='lvlm_summary_report.json',
                       help='è¾“å‡ºJSONæ–‡ä»¶')
    
    args = parser.parse_args()
    
    print("ğŸ”„ åŠ è½½LVLMè¯„ä¼°ç»“æœ...")
    results = load_lvlm_results(args.input_dir)
    
    if not results:
        print("âŒ æœªæ‰¾åˆ°è¯„ä¼°ç»“æœ")
        return
    
    print(f"   âœ“ æ‰¾åˆ° {len(results)} ä¸ªCLIPæ¨¡å‹çš„ç»“æœ")
    
    # ä¿å­˜JSON
    output_data = {
        'results': dict(results),
        'timestamp': datetime.now().isoformat()
    }
    
    with open(args.output_file, 'w') as f:
        json.dump(output_data, f, indent=2)
    print(f"   âœ“ å·²ä¿å­˜: {args.output_file}")
    
    # ç”ŸæˆMarkdownæŠ¥å‘Š
    md_file = args.output_file.replace('.json', '.md')
    md_content = generate_markdown_report(results)
    with open(md_file, 'w') as f:
        f.write(md_content)
    print(f"   âœ“ å·²ä¿å­˜: {md_file}")
    
    print("\nâœ… æ±‡æ€»å®Œæˆ!")


if __name__ == '__main__':
    main()
