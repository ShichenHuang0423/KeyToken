#!/usr/bin/env python
"""
KeyToken å¿«é€Ÿæµ‹è¯•è„šæœ¬
ç”¨äºéªŒè¯ç¯å¢ƒé…ç½®å’Œæ¨¡å‹åŠ è½½æ˜¯å¦æ­£å¸¸
"""

import sys
import torch
from PIL import Image
import requests
from io import BytesIO

def print_section(title):
    """æ‰“å°åˆ†èŠ‚æ ‡é¢˜"""
    print("\n" + "="*60)
    print(f"  {title}")
    print("="*60)

def test_imports():
    """æµ‹è¯•å…³é”®åº“å¯¼å…¥"""
    print_section("æµ‹è¯• 1: æ£€æŸ¥ä¾èµ–åº“å¯¼å…¥")
    
    required_libs = [
        'torch', 'torchvision', 'open_clip', 'transformers', 
        'accelerate', 'einops', 'huggingface_hub', 'PIL',
        'numpy', 'wandb', 'timm'
    ]
    
    failed = []
    for lib in required_libs:
        try:
            __import__(lib)
            print(f"  âœ“ {lib}")
        except ImportError as e:
            print(f"  âœ— {lib}: {e}")
            failed.append(lib)
    
    if failed:
        print(f"\nè­¦å‘Š: {len(failed)} ä¸ªåº“å¯¼å…¥å¤±è´¥")
        return False
    else:
        print("\næ‰€æœ‰ä¾èµ–åº“å¯¼å…¥æˆåŠŸï¼")
        return True

def test_cuda():
    """æµ‹è¯•CUDAå¯ç”¨æ€§"""
    print_section("æµ‹è¯• 2: CUDAç¯å¢ƒæ£€æŸ¥")
    
    print(f"  PyTorchç‰ˆæœ¬: {torch.__version__}")
    print(f"  CUDAå¯ç”¨: {torch.cuda.is_available()}")
    
    if torch.cuda.is_available():
        print(f"  CUDAç‰ˆæœ¬: {torch.version.cuda}")
        print(f"  cuDNNç‰ˆæœ¬: {torch.backends.cudnn.version()}")
        print(f"  GPUæ•°é‡: {torch.cuda.device_count()}")
        for i in range(torch.cuda.device_count()):
            print(f"  GPU {i}: {torch.cuda.get_device_name(i)}")
            # æ˜¾ç¤ºæ˜¾å­˜
            mem_total = torch.cuda.get_device_properties(i).total_memory / 1e9
            print(f"    æ˜¾å­˜: {mem_total:.2f} GB")
        return True
    else:
        print("  è­¦å‘Š: æœªæ£€æµ‹åˆ°CUDAæ”¯æŒï¼Œå°†ä½¿ç”¨CPUè¿è¡Œï¼ˆé€Ÿåº¦è¾ƒæ…¢ï¼‰")
        return False

def test_clip_model_loading():
    """æµ‹è¯•CLIPæ¨¡å‹åŠ è½½"""
    print_section("æµ‹è¯• 3: CLIPæ¨¡å‹åŠ è½½")
    
    try:
        import open_clip
        
        print("  æ­£åœ¨åŠ è½½OpenAI ViT-L/14 CLIPæ¨¡å‹...")
        model, _, preprocess = open_clip.create_model_and_transforms(
            'ViT-L-14', 
            pretrained='openai',
            device='cpu'  # å…ˆåœ¨CPUæµ‹è¯•
        )
        print("  âœ“ æ¨¡å‹åŠ è½½æˆåŠŸ")
        
        # ç»Ÿè®¡å‚æ•°é‡
        total_params = sum(p.numel() for p in model.parameters())
        print(f"  æ¨¡å‹å‚æ•°é‡: {total_params/1e6:.2f}M")
        
        # æµ‹è¯•å‰å‘ä¼ æ’­
        print("  æ­£åœ¨æµ‹è¯•å‰å‘ä¼ æ’­...")
        dummy_image = torch.randn(1, 3, 224, 224)
        dummy_text = open_clip.tokenize(["a photo of a cat"])
        
        with torch.no_grad():
            image_features = model.encode_image(dummy_image)
            text_features = model.encode_text(dummy_text)
        
        print(f"  âœ“ å›¾åƒç‰¹å¾ç»´åº¦: {image_features.shape}")
        print(f"  âœ“ æ–‡æœ¬ç‰¹å¾ç»´åº¦: {text_features.shape}")
        
        return True
        
    except Exception as e:
        print(f"  âœ— æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return False

def test_image_inference():
    """æµ‹è¯•å›¾åƒæ¨ç†"""
    print_section("æµ‹è¯• 4: å›¾åƒæ¨ç†æµ‹è¯•")
    
    try:
        import open_clip
        from PIL import Image
        
        print("  æ­£åœ¨ä¸‹è½½æµ‹è¯•å›¾ç‰‡...")
        # ä½¿ç”¨ä¸€ä¸ªå…¬å¼€çš„æµ‹è¯•å›¾ç‰‡
        url = "https://raw.githubusercontent.com/openai/CLIP/main/CLIP.png"
        try:
            response = requests.get(url, timeout=10)
            image = Image.open(BytesIO(response.content)).convert('RGB')
            print("  âœ“ å›¾ç‰‡ä¸‹è½½æˆåŠŸ")
        except:
            print("  ! æ— æ³•ä¸‹è½½æµ‹è¯•å›¾ç‰‡ï¼Œåˆ›å»ºéšæœºå›¾ç‰‡")
            image = Image.new('RGB', (224, 224), color='red')
        
        print("  æ­£åœ¨åŠ è½½æ¨¡å‹...")
        model, _, preprocess = open_clip.create_model_and_transforms(
            'ViT-L-14', 
            pretrained='openai',
            device='cpu'
        )
        
        # é¢„å¤„ç†å›¾ç‰‡
        image_tensor = preprocess(image).unsqueeze(0)
        
        # å®šä¹‰ç±»åˆ«
        text_labels = ["a dog", "a cat", "a bird", "a car", "a building"]
        text_tokens = open_clip.tokenize(text_labels)
        
        print("  æ­£åœ¨è¿›è¡Œé›¶æ ·æœ¬åˆ†ç±»...")
        with torch.no_grad():
            image_features = model.encode_image(image_tensor)
            text_features = model.encode_text(text_tokens)
            
            # å½’ä¸€åŒ–
            image_features = image_features / image_features.norm(dim=-1, keepdim=True)
            text_features = text_features / text_features.norm(dim=-1, keepdim=True)
            
            # è®¡ç®—ç›¸ä¼¼åº¦
            similarity = (100.0 * image_features @ text_features.T).softmax(dim=-1)
        
        print("\n  é¢„æµ‹ç»“æœ:")
        for label, prob in zip(text_labels, similarity[0]):
            print(f"    {label:15s}: {prob.item()*100:5.2f}%")
        
        print("\n  âœ“ æ¨ç†æµ‹è¯•æˆåŠŸ")
        return True
        
    except Exception as e:
        print(f"  âœ— æ¨ç†æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_project_structure():
    """æµ‹è¯•é¡¹ç›®ç»“æ„"""
    print_section("æµ‹è¯• 5: é¡¹ç›®ç»“æ„æ£€æŸ¥")
    
    import os
    
    required_dirs = [
        'train', 'CLIP_eval', 'CLIP_benchmark', 'vlm_eval',
        'pope_eval', 'scienceqa_eval', 'llava', 'open_flamingo',
        'bash', 'autoattack'
    ]
    
    required_files = [
        'requirements.txt', 'README.md', 'SETUP_GUIDE.md'
    ]
    
    missing_dirs = []
    missing_files = []
    
    for dir_name in required_dirs:
        if os.path.isdir(dir_name):
            print(f"  âœ“ {dir_name}/")
        else:
            print(f"  âœ— {dir_name}/ (ç¼ºå¤±)")
            missing_dirs.append(dir_name)
    
    for file_name in required_files:
        if os.path.isfile(file_name):
            print(f"  âœ“ {file_name}")
        else:
            print(f"  ! {file_name} (ç¼ºå¤±)")
            missing_files.append(file_name)
    
    if missing_dirs:
        print(f"\n  è­¦å‘Š: {len(missing_dirs)} ä¸ªå¿…éœ€ç›®å½•ç¼ºå¤±")
        return False
    
    print("\n  é¡¹ç›®ç»“æ„å®Œæ•´")
    return True

def test_huggingface_connection():
    """æµ‹è¯•HuggingFaceè¿æ¥"""
    print_section("æµ‹è¯• 6: HuggingFaceè¿æ¥")
    
    try:
        from huggingface_hub import hf_hub_download
        print("  æ­£åœ¨æµ‹è¯•HuggingFace Hubè¿æ¥...")
        
        # å°è¯•è®¿é—®ä¸€ä¸ªå…¬å¼€çš„é…ç½®æ–‡ä»¶ï¼ˆå¾ˆå°ï¼Œä¸ä¼šçœŸæ­£ä¸‹è½½å¤§æ–‡ä»¶ï¼‰
        try:
            # åªæ˜¯æ£€æŸ¥èƒ½å¦è®¿é—®ï¼Œä¸å®é™…ä¸‹è½½
            from huggingface_hub import model_info
            info = model_info("openai/clip-vit-large-patch14")
            print(f"  âœ“ æˆåŠŸè¿æ¥åˆ°HuggingFace Hub")
            print(f"  âœ“ æµ‹è¯•æ¨¡å‹: {info.modelId}")
            return True
        except Exception as e:
            print(f"  ! è¿æ¥HuggingFaceå¯èƒ½è¾ƒæ…¢æˆ–éœ€è¦ä»£ç†: {e}")
            print("  æç¤º: å¦‚åœ¨å›½å†…ï¼Œå¯è®¾ç½®é•œåƒ:")
            print("    export HF_ENDPOINT=https://hf-mirror.com")
            return False
            
    except Exception as e:
        print(f"  âœ— æµ‹è¯•å¤±è´¥: {e}")
        return False

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("\n" + "+"*60)
    print("  KeyToken (RobustVLM) ç¯å¢ƒéªŒè¯æµ‹è¯•")
    print("+"*60)
    
    results = []
    
    # è¿è¡Œæ‰€æœ‰æµ‹è¯•
    results.append(("ä¾èµ–åº“å¯¼å…¥", test_imports()))
    results.append(("CUDAç¯å¢ƒ", test_cuda()))
    results.append(("CLIPæ¨¡å‹åŠ è½½", test_clip_model_loading()))
    results.append(("å›¾åƒæ¨ç†", test_image_inference()))
    results.append(("é¡¹ç›®ç»“æ„", test_project_structure()))
    results.append(("HuggingFaceè¿æ¥", test_huggingface_connection()))
    
    # æ€»ç»“
    print_section("æµ‹è¯•æ€»ç»“")
    
    passed = sum(1 for _, result in results if result)
    total = len(results)
    
    for name, result in results:
        status = "âœ“ é€šè¿‡" if result else "âœ— å¤±è´¥"
        print(f"  {name:20s}: {status}")
    
    print(f"\n  æ€»è®¡: {passed}/{total} æµ‹è¯•é€šè¿‡")
    
    if passed == total:
        print("\n  ğŸ‰ æ­å–œï¼æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼Œç¯å¢ƒé…ç½®å®Œæˆï¼")
        print("\n  ä¸‹ä¸€æ­¥:")
        print("    1. æŸ¥çœ‹ SETUP_GUIDE.md äº†è§£è¯¦ç»†ä½¿ç”¨è¯´æ˜")
        print("    2. ä¸‹è½½æ•°æ®é›†ï¼ˆå‚è€ƒSETUP_GUIDE.mdä¸­çš„æ•°æ®é›†å‡†å¤‡éƒ¨åˆ†ï¼‰")
        print("    3. è¿è¡Œå®éªŒï¼ˆå‚è€ƒSETUP_GUIDE.mdä¸­çš„å®éªŒå¤ç°æ­¥éª¤ï¼‰")
        return 0
    else:
        print("\n  âš ï¸  éƒ¨åˆ†æµ‹è¯•æœªé€šè¿‡ï¼Œè¯·æ£€æŸ¥ç¯å¢ƒé…ç½®")
        print("     å‚è€ƒ SETUP_GUIDE.md ä¸­çš„æ•…éšœæ’é™¤éƒ¨åˆ†")
        return 1

if __name__ == "__main__":
    sys.exit(main())
