#!/bin/bash

# æ¸è¿›å¼è§£å†»è®­ç»ƒè„šæœ¬ - äº¤äº’å¼é˜¶æ®µé€‰æ‹© (æ˜¾å­˜ä¼˜åŒ–ç‰ˆ v2)
# æ”¯æŒé˜¶æ®µ0-4ï¼šå®Œå…¨è§£å†»/å†»ç»“backbone/æ¸è¿›è§£å†»
# âš¡ æ˜¾å­˜ä¼˜åŒ–ï¼šæ”¯æŒAMPæ··åˆç²¾åº¦è®­ç»ƒã€æ¢¯åº¦ç´¯ç§¯

echo "================================================"
echo "  KeyToken æ¸è¿›å¼è§£å†»è®­ç»ƒ (æ˜¾å­˜ä¼˜åŒ–ç‰ˆ)"
echo "  æ•°æ®é›†: ImageNet (128ä¸‡å›¾åƒ)"
echo "  GPU: 4x RTX 4090 (GPU 1-4, ç¨³å®šé…ç½®)"
echo "  âš¡ æ–°å¢: AMPæ··åˆç²¾åº¦ + æ¢¯åº¦ç´¯ç§¯"
echo "================================================"
echo ""
echo "ğŸ†• ä»£ç ç‰ˆæœ¬: v2.0 - Attack Mode (2024-12-21)"
echo "   âœ… å¯¹æŠ—æ ·æœ¬ç”Ÿæˆä½¿ç”¨attackæ¨¡å¼ï¼ˆæ— é˜²å¾¡ï¼‰"
echo "   âœ… è®­ç»ƒæ—¶ä½¿ç”¨trainæ¨¡å¼ï¼ˆå®Œæ•´å¢å¼ºï¼‰"
echo "   âœ… é¢„æœŸFeatDiff: 0.05-0.15ï¼ˆæ˜¾è‘—æå‡ï¼‰"
echo "================================================"
echo ""
echo "è¯·é€‰æ‹©è®­ç»ƒé˜¶æ®µï¼š"
echo "  0 - å®Œå…¨è§£å†»è®­ç»ƒ (å¸¸è§„è®­ç»ƒï¼Œä¸å†»ç»“ï¼Œ4 epochs)"
echo "  1 - é˜¶æ®µ1: å†»ç»“CLIP backbone (åªè®­ç»ƒæ–°å¢æ¨¡å—, 1 epoch)"
echo "  2 - é˜¶æ®µ2: è§£å†»å6å±‚ (ä»é˜¶æ®µ1æ¢å¤, 1.2 epochs)"
echo "  3 - é˜¶æ®µ3: è§£å†»å12å±‚ (ä»é˜¶æ®µ2æ¢å¤, 1 epoch)"
echo "  4 - é˜¶æ®µ4: å®Œå…¨è§£å†»å¾®è°ƒ (ä»é˜¶æ®µ3æ¢å¤, 1 epoch)"
echo ""
read -p "è¾“å…¥é˜¶æ®µç¼–å· (0-4): " STAGE

# éªŒè¯è¾“å…¥
if ! [[ "$STAGE" =~ ^[0-4]$ ]]; then
    echo "âŒ æ— æ•ˆè¾“å…¥ï¼è¯·è¾“å…¥0-4ä¹‹é—´çš„æ•°å­—"
    exit 1
fi

# æ¿€æ´»ç¯å¢ƒ
source ~/miniconda3/etc/profile.d/conda.sh
conda activate keytoken

# è®¡ç®—ï¼šImageNetçº¦128ä¸‡å›¾åƒï¼Œ4 GPU
# 4å¡é…ç½®æ›´ç¨³å®šï¼Œé¿å…æ»¡åŠŸè€—å´©æºƒé£é™©

# âš¡ æ˜¾å­˜ä¸I/Oä¼˜åŒ–å‚æ•° (é»˜è®¤å¼€å¯)
USE_AMP="True"              # æ··åˆç²¾åº¦è®­ç»ƒï¼ŒèŠ‚çœ~30%æ˜¾å­˜
GRADIENT_ACCUMULATION=3     # æ¢¯åº¦ç´¯ç§¯æ­¥æ•°ï¼Œæœ‰æ•ˆbatch=batch_size*accumulation
MEMORY_EFFICIENT="True"     # å†…å­˜é«˜æ•ˆæ¨¡å¼

# ğŸš¨ I/Oä¼˜åŒ–ï¼šé’ˆå¯¹HDDç£ç›˜ç“¶é¢ˆ
# - ç£ç›˜ä½¿ç”¨ç‡94%ï¼Œéœ€è¦æè‡´ä¼˜åŒ–I/O
# - é™ä½DataLoader workersé¿å…éšæœºI/O
NUM_WORKERS=2               # HDDä¸¥é‡ç“¶é¢ˆæ—¶é™åˆ°2 (åŸ4)
PREFETCH_FACTOR=2           # é™ä½é¢„è¯»å–ï¼Œå‡å°‘I/Oå‹åŠ› (åŸ4)

# æ ¹æ®é˜¶æ®µè®¾ç½®å‚æ•°
case $STAGE in
    0)
        STAGE_NAME="stage0_full_training"
        # é‡æ–°è®¡ç®—ï¼š4 GPU Ã— 12/GPU = 48æ€»batchï¼ˆå®é™…batch sizeï¼‰
        # æ¯ä¸ªepoch â‰ˆ 1,281,167 / 48 â‰ˆ 26,690 steps
        # 4 epochs = 106,760 steps
        STEPS=106760
        WARMUP=5000
        # âš¡ RTX 4090 24GBç¨³å®šé…ç½® (4å¡)
        # - å•å¡batch_size=12ï¼Œå®‰å…¨è£•åº¦å……è¶³
        # - æ¢¯åº¦ç´¯ç§¯3å€ = æœ‰æ•ˆbatch 144
        BATCH_SIZE=48
        GRADIENT_ACCUMULATION=3
        LR="1e-5"
        FREEZE_BACKBONE="False"
        FREEZE_LAYERS=0
        RESUME=""
        SEED=42  # ğŸ² Stage 0ç‹¬ç«‹è®­ç»ƒé“¾çš„å›ºå®šç§å­
        EPOCHS=4
        DESC="å®Œå…¨è§£å†»è®­ç»ƒ (4 epochs, 4090ä¼˜åŒ–)"
        ;;
    1)
        STAGE_NAME="stage1_freeze_all"
        # âš¡ ä¼˜åŒ–æ˜¾å­˜åˆ©ç”¨ç‡ï¼ˆ24GBæ˜¾å­˜åº”å……åˆ†ä½¿ç”¨ï¼‰
        # - å†»ç»“æ—¶æ˜¾å­˜éœ€æ±‚å°ï¼Œå¯ä»¥ç”¨æ›´å¤§batch
        # - æ¯å¡batch=32ï¼Œ4å¡æ€»batch=128
        # - æ¯ä¸ªepoch = 1,281,167 / 128 â‰ˆ 10,009 dataloaderè¿­ä»£
        # - optimizeræ­¥æ•° = 10,009 / 2 â‰ˆ 5,005 æ­¥
        # - é¢„æœŸæ˜¾å­˜ï¼š~12-15GB/å¡ (50-60%åˆ©ç”¨ç‡)
        STEPS=5005
        WARMUP=500
        BATCH_SIZE=128  # 4å¡ Ã— 32/å¡ï¼Œå……åˆ†åˆ©ç”¨æ˜¾å­˜
        GRADIENT_ACCUMULATION=2
        LR="5e-4"
        FREEZE_BACKBONE="True"
        FREEZE_LAYERS=0
        RESUME=""
        SEED=123  # ğŸ² Stage 1-4æ¸è¿›å¼è®­ç»ƒé“¾çš„èµ·ç‚¹ç§å­ï¼ˆä¸Stage 0ä¸åŒï¼‰
        EPOCHS=1
        DESC="å†»ç»“CLIP backbone (1 epoch)"
        ;;
    2)
        STAGE_NAME="stage2_unfreeze_6layers"
        # âš¡ ä¼˜åŒ–æ˜¾å­˜åˆ©ç”¨ç‡ï¼šè§£å†»6å±‚åæ˜¾å­˜éœ€æ±‚å¢åŠ 
        # - æ¯å¡batch=24ï¼Œ4å¡æ€»batch=96
        # - æ¯ä¸ªepoch = 1,281,167 / 96 â‰ˆ 13,345 dataloaderè¿­ä»£
        # - optimizeræ­¥æ•° = 13,345 / 2 â‰ˆ 6,673 æ­¥
        # - 1.2 epochs = 6,673 Ã— 1.2 â‰ˆ 8,008 æ­¥
        # - é¢„æœŸæ˜¾å­˜ï¼š~15-18GB/å¡ (60-75%åˆ©ç”¨ç‡)
        STEPS=8008
        WARMUP=500
        BATCH_SIZE=96  # 4å¡ Ã— 24/å¡
        GRADIENT_ACCUMULATION=2
        LR="3e-4"
        FREEZE_BACKBONE="True"
        FREEZE_LAYERS=18
        RESUME="output/stage1_freeze_all/checkpoints/epoch_1.pt"
        SEED=""  # ğŸ² ä»checkpointæ¢å¤ï¼Œç»§æ‰¿Stage 1çš„ç§å­
        EPOCHS="1.2"
        DESC="è§£å†»å6å±‚ (ä»Stage1ç»­)"
        ;;
    3)
        STAGE_NAME="stage3_unfreeze_12layers"
        # âš¡ ä¼˜åŒ–æ˜¾å­˜åˆ©ç”¨ç‡ï¼šè§£å†»12å±‚æ˜¾å­˜éœ€æ±‚æ›´å¤§
        # - æ¯å¡batch=20ï¼Œ4å¡æ€»batch=80
        # - æ¯ä¸ªepoch = 1,281,167 / 80 â‰ˆ 16,015 dataloaderè¿­ä»£
        # - optimizeræ­¥æ•° = 16,015 / 2 â‰ˆ 8,008 æ­¥
        # - é¢„æœŸæ˜¾å­˜ï¼š~16-19GB/å¡ (65-80%åˆ©ç”¨ç‡)
        STEPS=8008
        WARMUP=500
        BATCH_SIZE=80  # 4å¡ Ã— 20/å¡
        GRADIENT_ACCUMULATION=2
        LR="1e-4"
        FREEZE_BACKBONE="True"
        FREEZE_LAYERS=12
        RESUME="output/stage2_unfreeze_6layers/checkpoints/epoch_2.pt"
        SEED=""  # ğŸ² ä»checkpointæ¢å¤ï¼Œç»§æ‰¿Stage 2çš„ç§å­
        EPOCHS=1
        DESC="è§£å†»å12å±‚ (ä»Stage2ç»­)"
        ;;
    4)
        STAGE_NAME="stage4_full_finetune"
        # âš¡ ä¼˜åŒ–æ˜¾å­˜åˆ©ç”¨ç‡ï¼šå®Œå…¨è§£å†»æ˜¾å­˜éœ€æ±‚æœ€å¤§
        # - æ¯å¡batch=16ï¼Œ4å¡æ€»batch=64
        # - æ¯ä¸ªepoch = 1,281,167 / 64 â‰ˆ 20,019 dataloaderè¿­ä»£
        # - optimizeræ­¥æ•° = 20,019 / 2 â‰ˆ 10,010 æ­¥
        # - é¢„æœŸæ˜¾å­˜ï¼š~18-21GB/å¡ (75-85%åˆ©ç”¨ç‡)
        STEPS=10010
        WARMUP=500
        BATCH_SIZE=64  # 4å¡ Ã— 16/å¡
        GRADIENT_ACCUMULATION=2
        LR="5e-5"
        FREEZE_BACKBONE="False"
        FREEZE_LAYERS=0
        RESUME="output/stage3_unfreeze_12layers/checkpoints/epoch_3.pt"
        SEED=""  # ğŸ² ä»checkpointæ¢å¤ï¼Œç»§æ‰¿Stage 3çš„ç§å­
        EPOCHS=1
        DESC="å®Œå…¨è§£å†»å¾®è°ƒ (ä»Stage3ç»­)"
        ;;
esac

# åˆ›å»ºè¾“å‡ºç›®å½•
mkdir -p output/${STAGE_NAME}/checkpoints

echo ""
echo "================================================"
echo "  è®­ç»ƒé…ç½®"
echo "================================================"
echo "é˜¶æ®µ: Stage $STAGE - $DESC"
echo "è¾“å‡ºç›®å½•: output/${STAGE_NAME}"
echo "è®­ç»ƒæ­¥æ•°: $STEPS steps (~$EPOCHS epoch)"
echo "Batch Size: $BATCH_SIZE (æ¯GPU: $((BATCH_SIZE/4)))"
echo "æ¢¯åº¦ç´¯ç§¯: $GRADIENT_ACCUMULATION (æœ‰æ•ˆbatch: $((BATCH_SIZE*GRADIENT_ACCUMULATION)))"
echo "å­¦ä¹ ç‡: $LR"
echo "Warmup: $WARMUP steps"
echo "å†»ç»“ç­–ç•¥: backbone=$FREEZE_BACKBONE, layers=$FREEZE_LAYERS"
echo ""
echo "âš¡ æ˜¾å­˜ä¼˜åŒ–:"
echo "   æ··åˆç²¾åº¦(AMP): $USE_AMP"
echo "   å†…å­˜é«˜æ•ˆæ¨¡å¼: $MEMORY_EFFICIENT"
echo ""
echo "ğŸš¨ I/Oä¼˜åŒ– (é’ˆå¯¹HDDç£ç›˜ç“¶é¢ˆ):"
echo "   DataLoader workers: $NUM_WORKERS (é™ä½éšæœºI/O)"
echo "   Prefetch factor: $PREFETCH_FACTOR (å‡å°‘I/Oå‹åŠ›)"
echo "   âš ï¸  ç£ç›˜ä½¿ç”¨ç‡94%ï¼Œè¯·å®šæœŸæ¸…ç†ç©ºé—´"
if [ ! -z "$RESUME" ]; then
    echo "æ¢å¤è‡ª: $RESUME"
fi
echo "================================================"
echo ""
read -p "æŒ‰Enterå¼€å§‹è®­ç»ƒï¼Œæˆ–Ctrl+Cå–æ¶ˆ..."
echo ""

# å¼€å§‹è®­ç»ƒ
echo "å¼€å§‹è®­ç»ƒ Stage $STAGE (åå°è¿è¡Œ)..."
echo "æ—¥å¿—è¾“å‡º: output/${STAGE_NAME}/train.log"
echo ""

# ä½¿ç”¨nohupåå°è¿è¡Œï¼ŒCUDA_VISIBLE_DEVICESåœ¨å‘½ä»¤è¡Œè®¾ç½®é¿å…ç¯å¢ƒå˜é‡é—®é¢˜
# âš¡ æ–°å¢æ˜¾å­˜ä¼˜åŒ–å‚æ•°: use_amp, gradient_accumulation_steps, memory_efficient_mode

# æ„å»ºåŸºç¡€å‘½ä»¤
CMD="CUDA_VISIBLE_DEVICES=0,1,2,3 nohup python -u -m train.adversarial_training_clip_enhanced \
    --clip_model_name ViT-L-14 \
    --pretrained models/fare_eps_4.pt \
    --dataset imagenet \
    --imagenet_root ~/data/KeyToken/datasets/imagenet \
    --steps $STEPS \
    --warmup $WARMUP \
    --batch_size $BATCH_SIZE \
    --lr $LR \
    --wd 1e-4 \
    --opt adamw \
    --attack pgd \
    --inner_loss l2 \
    --norm linf \
    --eps 4 \
    --iterations_adv 10 \
    --stepsize_adv 1 \
    --use_keytoken_loss True \
    --contrastive_weight 1.0 \
    --contrastive_temperature 0.07 \
    --robust_weight 0.1 \
    --detect_weight 0.1 \
    --use_mae_recon True \
    --use_key_token_protection True \
    --mae_weight 1.0 \
    --text_recon_weight 0.8 \
    --key_token_ratio 0.2 \
    --mask_ratio 0.5 \
    --adaptive_masking False \
    --freeze_clip_backbone $FREEZE_BACKBONE \
    --freeze_encoder_layers $FREEZE_LAYERS \
    --use_amp $USE_AMP \
    --gradient_accumulation_steps $GRADIENT_ACCUMULATION \
    --memory_efficient_mode $MEMORY_EFFICIENT \
    --num_workers $NUM_WORKERS \
    --prefetch_factor $PREFETCH_FACTOR \
    --experiment_name \"${STAGE_NAME}\" \
    --output_dir output/${STAGE_NAME} \
    --overwrite False \
    --wandb False \
    --log_freq 10 \
    --eval_freq 10 \
    --save_checkpoints True \
    --checkpoint_freq 2000 \
    --resume \"$RESUME\""

# åªåœ¨SEEDéç©ºæ—¶æ·»åŠ --seedå‚æ•°
if [ ! -z "$SEED" ]; then
    CMD="$CMD --seed $SEED"
fi

# æ‰§è¡Œå‘½ä»¤
eval "$CMD > output/${STAGE_NAME}/train.log 2>&1 &"

# ä¿å­˜è®­ç»ƒè¿›ç¨‹PID
TRAIN_PID=$!
echo $TRAIN_PID > output/${STAGE_NAME}/train.pid

echo ""
echo "================================================"
echo "  Stage $STAGE è®­ç»ƒå·²å¯åŠ¨ï¼ˆåå°è¿è¡Œï¼‰"
echo "================================================"
echo " è¿›ç¨‹ID: $TRAIN_PID"
echo ""
echo " ç›‘æ§å‘½ä»¤:"
echo "   å®æ—¶æ—¥å¿—: tail -f output/${STAGE_NAME}/train.log"
echo "   æŸ¥çœ‹è¿›ç¨‹: ps -p $TRAIN_PID"
echo "   GPUçŠ¶æ€: watch -n 2 nvidia-smi"
echo "   åœæ­¢è®­ç»ƒ: kill $TRAIN_PID"
echo ""
echo " æŸ¥çœ‹è®­ç»ƒè¿›åº¦:"
echo "   grep 'Step' output/${STAGE_NAME}/train.log | tail -10"
echo ""
echo " ç‰¹å¾å·®å¼‚åˆ†æ:"
echo "   grep 'FeatDiff' output/${STAGE_NAME}/train.log | tail -20"
echo ""
if [ "$STAGE" == "1" ]; then
    echo " ä¸‹ä¸€æ­¥: è¿è¡Œ Stage 2 (è§£å†»å6å±‚)"
    echo "   bash bash/train_enhanced_4epochs.sh  # é€‰æ‹© 2"
elif [ "$STAGE" == "2" ]; then
    echo " ä¸‹ä¸€æ­¥: è¿è¡Œ Stage 3 (è§£å†»å12å±‚)"
    echo "   bash bash/train_enhanced_4epochs.sh  # é€‰æ‹© 3"
elif [ "$STAGE" == "3" ]; then
    echo " ä¸‹ä¸€æ­¥: è¿è¡Œ Stage 4 (å®Œå…¨è§£å†»å¾®è°ƒï¼Œå¯é€‰)"
    echo "   bash bash/train_enhanced_4epochs.sh  # é€‰æ‹© 4"
fi
echo "================================================"
echo ""
echo "æç¤º: SSHæ–­å¼€åè®­ç»ƒä¼šç»§ç»­è¿è¡Œ"
echo "é‡æ–°ç™»å½•åå¯ç”¨ä»¥ä¸‹å‘½ä»¤ç›‘æ§:"
echo "  tail -f output/${STAGE_NAME}/train.log"
echo ""
